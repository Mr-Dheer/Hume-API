{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kavach/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/kavach/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/kavach/miniconda3/envs/tfenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# %conda install  beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "# %conda install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')  # Needed the first time you use NLTK's tokenizers\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import pipeline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Function to clean the DataFrame and convert it to a list\n",
    "def clean_dataframe_and_convert_to_list(df):\n",
    "    def strip_html(text):\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        return soup.get_text()\n",
    "\n",
    "    def remove_between_square_brackets(text):\n",
    "        return re.sub(r'\\[[^]]*\\]', '', text)\n",
    "\n",
    "    def denoise_text(text):\n",
    "        text = strip_html(text)\n",
    "        text = remove_between_square_brackets(text)\n",
    "        return text\n",
    "\n",
    "    def remove_special_characters(text, remove_digits=True):\n",
    "        pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "        text = re.sub(pattern, '', text)\n",
    "        return text\n",
    "    \n",
    "    # Apply the cleaning functions\n",
    "    df['Content'] = df['Content'].apply(lambda x: x.lower())\n",
    "    df['Content'] = df['Content'].apply(denoise_text)\n",
    "    df['Content'] = df['Content'].apply(remove_special_characters)\n",
    "    \n",
    "    # Convert the DataFrame into a list of dictionaries\n",
    "    result_list = df.to_dict('records')\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "# Function to fetch reviews and return cleaned data as a list of dictionaries\n",
    "def fetch_reviews_to_df(movie_id):\n",
    "    api_key = '472483140ad07905a27f7ff2eed59152'\n",
    "    response = requests.get(f\"https://api.themoviedb.org/3/movie/{movie_id}/reviews?api_key={api_key}&language=en-US\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        reviews = data.get('results', [])\n",
    "        \n",
    "        reviews_data = []\n",
    "        for review in reviews[:4]:  # Limit to first 4 reviews\n",
    "            review_dict = {\n",
    "                \"Author\": review.get('author'),\n",
    "                \"Content\": review.get('content')\n",
    "            }\n",
    "            reviews_data.append(review_dict)\n",
    "        \n",
    "        # Convert list of dictionaries to DataFrame\n",
    "        df_reviews = pd.DataFrame(reviews_data)\n",
    "        \n",
    "        # Clean the DataFrame and convert it back to a list of dictionaries\n",
    "        cleaned_reviews_list = clean_dataframe_and_convert_to_list(df_reviews)\n",
    "        \n",
    "        return cleaned_reviews_list\n",
    "    else:\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Author': 'Andre Gonzales',\n",
       "  'Content': 'part  jack is stuck in davy jones locker while he is stuck the biggest war is being set to happen jack and the others try to free him from davy jones locker before the war comes very good movie as well kind of boring at times though'},\n",
       " {'Author': 'CinemaSerf',\n",
       "  'Content': 'now this is just far far too long at ten minutes shy of three hours the story just isnt substantial enough to sustain it and i must confess to finding my attention dwindling a bit at various stages of the proceedings thankfully geoffrey rush has rejoined the cast as the whole ensemble must now risk life and limb  and sail to the very edge of the world  to save jack johnny depp from oblivion and thwart the seemingly unstoppable lord beckett tom hollander how to do this well they must galvanise the entire global pirate community and that means the dreaded sao feng chow yunfat capt teague the one and only keith richards and a consortium of the most corrupt venal and treacherous folks ever put on earth this time though it is elizabeth keira knightley who steps up to the plate and demonstrates that she has come a long way since she was kidnapped from her fathers home just a few short years ago to become a true kickass captain in her own right this has much less of a story than the first two films it sort of rehashes the tail end of the story from dead mans chest  just a bit too much and although the visual effects are superb as usual the whole thing just looked more like a victory for the marketing executives than the creative ones at disney the last half hour is all good fun though with a denouement that we could have had half an hour earlier and that would have served as a fitting conclusion to the adventures of this disparate band of pirates lovers and scaly monsters its still watchable but i fear this is all a bit tired and verbinski et al are really struggling for that innovation that we have seen before'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_reviews_to_df(285)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movieRecSys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
